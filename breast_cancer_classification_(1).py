# -*- coding: utf-8 -*-
"""breast_cancer_classification (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KBOjff7K8nydGQtrF2oFXwnM41iuXXeM
"""

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

data=load_breast_cancer()
x=data.data
y=data.target

x

len(x)

x_train.shape

y

len(y)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
y_train.shape

scaler=StandardScaler()
x_train=scaler.fit_transform(x_train)
x_test=scaler.transform(x_test)

# convert data to PyTorch tensors and move it to GPU
x_train = torch.tensor(x_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
x_test = torch.tensor(x_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32)
print(y_train)

y_train.shape

y_test

class NeuralNetwork(nn.Module):
    def __init__(self,input_size,hidden_size,output_size):

        super(NeuralNetwork, self).__init__()
        self.fc1=nn.Linear(input_size,hidden_size)
        self.relu=nn.ReLU()
        self.fc2=nn.Linear(128,64)
        self.relu=nn.ReLU()
        self.fc3=nn.Linear(64,1)
        self.sigmoid=nn.Sigmoid()




    def forward(self, x):
         out = self.fc1(x)
         out = nn.ReLU()(out)  # Inline usage of activation
         out = self.fc2(out)
         out = nn.ReLU()(out)
         out = self.fc3(out)
         out = self.sigmoid(out)
         return out

input_size = x_train.shape[1]
hidden_size = 128
output_size = 1
learning_rate = 0.001
num_epochs = 100

model=NeuralNetwork(input_size,hidden_size,output_size)

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# training the model
for epoch in range(num_epochs):
  model.train()
  optimizer.zero_grad()
  outputs = model(x_train)
  loss = criterion(outputs, y_train.view(-1,1))
  loss.backward()
  optimizer.step()

  # claculate accuracy
  with torch.no_grad():
    predicted = outputs.round()
    correct = (predicted == y_train.view(-1,1)).float().sum()
    accuracy = correct/y_train.size(0)

  if (epoch+1) % 10 == 0:
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss : {loss.item():.4f}, Accuracy: {accuracy.item() * 100:.2f}%")

# evaluation on training set
model.eval()
with torch.no_grad():
  outputs = model(x_train)
  predicted = outputs.round()
  correct = (predicted == y_train.view(-1,1)).float().sum()
  accuracy = correct/y_train.size(0)
  print(f"Accuracy on training data: {accuracy.item() * 100:.2f}%")

# evaluation on test set
model.eval()
with torch.no_grad():
  outputs = model(x_test)
  predicted = outputs.round()
  correct = (predicted == y_test.view(-1,1)).float().sum()
  accuracy = correct/y_test.size(0)
  print(f"Accuracy on test data: {accuracy.item() * 100:.2f}%")